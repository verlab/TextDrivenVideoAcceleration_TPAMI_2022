{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3nxJ0VElkpO"
      },
      "source": [
        "### Prepare the data to train the Skip-Aware Fast-Forward Agent (SAFFA)\n",
        "\n",
        "- Clone the repo and install the dependencies (you may need to restart the session after running the following command once):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFWPY-CkNGNM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/verlab/TextDrivenVideoAcceleration_TPAMI_2022\n",
        "%cd TextDrivenVideoAcceleration_TPAMI_2022\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYgp6h47siRU"
      },
      "source": [
        "- To train the agent, you will need the features produced the VDAN+ model. You can have these features using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E44GxN1MshGm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Download YouCook2's VDAN+ video feats\n",
        "! wget -O rl_fast_forward/resources/YouCook2/VDAN+/youcook2_vdan+_vid_feats.zip https://verlab.dcc.ufmg.br/TextDrivenVideoAcceleration/youcook2_vdan+_vid_feats.zip\n",
        "! unzip -q rl_fast_forward/resources/YouCook2/VDAN+/youcook2_vdan+_vid_feats.zip -d rl_fast_forward/resources/YouCook2/VDAN+/vid_feats/\n",
        "! rm rl_fast_forward/resources/YouCook2/VDAN+/youcook2_vdan+_vid_feats.zip\n",
        "\n",
        "# Download YouCook2's VDAN+ document feats\n",
        "! wget -O rl_fast_forward/resources/YouCook2/VDAN+/youcook2_vdan+_doc_feats.zip https://verlab.dcc.ufmg.br/TextDrivenVideoAcceleration/youcook2_vdan+_doc_feats.zip\n",
        "! unzip -q rl_fast_forward/resources/YouCook2/VDAN+/youcook2_vdan+_doc_feats.zip -d rl_fast_forward/resources/YouCook2/VDAN+/doc_feats/\n",
        "! rm rl_fast_forward/resources/YouCook2/VDAN+/youcook2_vdan+_doc_feats.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT8FY0NK13-E"
      },
      "source": [
        "- If you want to extract them by yourself, you can have a VDAN pretrained model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob36PdmcizC3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Download the pretrained model\n",
        "%cd /content/TextDrivenVideoAcceleration_TPAMI_2022\n",
        "! wget -O semantic_encoding/models/vdan+_pretrained_model.pth https://github.com/verlab/TextDrivenVideoAcceleration_TPAMI_2022/releases/download/pre_release/vdan+_pretrained_model.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ink34FD2UAe"
      },
      "source": [
        "- Now, prepare the data for training...\n",
        "  1. First, download the annotations;\n",
        "  2. Then, download the videos, IF NECESSARY. **PS.: If you already have the VDAN features extracted, skip this step**;\n",
        "  3. Finally, prepare the recipe files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOhfi2rfroRR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# 1. Download and extract the annotations\n",
        "%cd /content/TextDrivenVideoAcceleration_TPAMI_2022\n",
        "! wget -O rl_fast_forward/resources/YouCook2/youcookii_annotations_trainval.tar.gz http://youcook2.eecs.umich.edu/static/YouCookII/youcookii_annotations_trainval.tar.gz\n",
        "! tar -xf rl_fast_forward/resources/YouCook2/youcookii_annotations_trainval.tar.gz -C rl_fast_forward/resources/YouCook2/\n",
        "! rm rl_fast_forward/resources/YouCook2/youcookii_annotations_trainval.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9idcdl7uONY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# 2. Download the scripts used to collect the videos + Install youtube-dl and download the available videos\n",
        "! wget -O rl_fast_forward/resources/YouCook2/scripts.tar.gz http://youcook2.eecs.umich.edu/static/YouCookII/scripts.tar.gz\n",
        "! tar -xf rl_fast_forward/resources/YouCook2/scripts.tar.gz -C rl_fast_forward/resources/YouCook2/\n",
        "! rm rl_fast_forward/resources/YouCook2/scripts.tar.gz\n",
        "\n",
        "! pip install youtube_dl\n",
        "%cd rl_fast_forward/resources/YouCook2/scripts\n",
        "! python download_youcookii_videos.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rpoXYNP2Sqf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# 3. Prepare the recipe files and feature folders\n",
        "%cd /content/TextDrivenVideoAcceleration_TPAMI_2022/rl_fast_forward/\n",
        "! python resources/create_youcook2_recipe_documents.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gMLAOFA2b8s"
      },
      "source": [
        "- You are set! Now, you just need to run it..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXT5Qa1j0LD_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "! python train.py -s ../semantic_encoding/models/vdan+_pretrained_model.pth -d YouCook2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FHmRnvJ2pG-"
      },
      "source": [
        "- After training, the model will be saved in the [rl_fast_forward/models](rl_fast_forward/models) folder. Then, the script will generate a results JSON file with the pattern `results/<datetime>_<hostname>_youcookii_selected_frames.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To evaluate the results, download the [YouCook2's ground-truth JSON file](https://github.com/verlab/TextDrivenVideoAcceleration_TPAMI_2022/releases/download/v1.0.0/youcookii_gts.json), then run the evaluation script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC2ZXM3Yhplc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "! wget https://github.com/verlab/TextDrivenVideoAcceleration_TPAMI_2022/releases/download/pre_release/youcookii_gts.json\n",
        "! python eval/eval_results.py -gt eval/youcookii_gts.json -sf results/<datetime>_<hostname>_youcookii_selected_frames.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- If you want to train using the COIN dataset, follow the same steps changing the folder names and annotation files accordingly. Please note that, to train in the COIN dataset you must also provide the domain on which you want to train the agent using the option -dm <DOMAIN_ACRONYM>. E.g., `python train.py -s ../semantic_encoding/models/vdan+_pretrained_model.pth -d DOIN -dm NC` for the domain Nursing and Care."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_SAFFA.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
